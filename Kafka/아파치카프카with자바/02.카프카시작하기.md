# Chapter 02 "카프카 빠르게 시작해보기"

> 목표: 실습용 카프카에서 토픽을 생성, 수정하고 데이터를 전송(프로듀서)하고 받는(컨슈머) 실습.

## 1. 실습용 카프카 브로커 설치

### 1.1. AWS EC2 인스턴스 발급 및 보안 설정

* EC2에서 인스턴스(가상 서버)를 발급받아서 설치 및 실행한다.
* AMI: 서버에 필요한 운영체제와 여러 소프트웨어가 조합된 템플릿
* AWS 네트워크 구성하기(VPC, Subnet, 보안그룹 등...)
    * [AWS 네트워크 구성하기](https://blog.naver.com/developer501/222686026403)
    * 보안 그룹 - 카프카 브로커의 기본 포트는 9092, 주키퍼의 기본 포트는 2181 이므로 Inbound 설정 OPEN
    * [EC2 인스턴스에 탄력적 IP 할당하기](https://blog.naver.com/010203sj/222712633709)
        * 퍼블릭 IP 주소는 유동 IP이기 때문에 인스턴스를 중지하고 다시 실행하게 되면 IP가 변경된다.<br>
        따라서 탄력적 IP를 할당받아서 인스턴스에 연결해야 한다.

### 1.2. 인스턴스에 접속하기

* Termius 이용
* AMI의 기본 username은 ec2-user

### 1.3. 인스턴스에 자바 설치

* 카프카 브로커는 스칼라와 자바로 작성되어 JVM 환경 위에서 실행된다.
* yum 사용하여 설치 (패키지 관리자로 패키지 검색/다운로드/설치)

```shell
$ yum list *openjdk*devel
Loaded plugins: extras_suggestions, langpacks, priorities, update-motd
Available Packages
java-1.7.0-openjdk-devel.x86_64                           1:1.7.0.261-2.6.22.2.amzn2.0.2                           amzn2-core
java-1.8.0-openjdk-devel.x86_64                           1:1.8.0.312.b07-1.amzn2.0.2                              amzn2-core

$ sudo yum install -y java-1.8.0-openjdk-devel.x86_64

$ java -version
openjdk version "1.8.0_312"
OpenJDK Runtime Environment (build 1.8.0_312-b07)
OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)
```

### 1.4. 주키퍼/카프카 브로커 실행

#### 1)  카프카 바이너리 패키지 다운로드
* 자바 소스코드를 컴파일하여 실행하기 위해 준비해 놓은 바이너리 파일이 들어있다.
* https://kafka.apache.org/downloads

```bash
$ wget https://dlcdn.apache.org/kafka/3.2.0/kafka_2.12-3.2.0.tgz

$ tar xvf kafka_2.12-3.2.0.tgz

$ ll
total 101564
drwxr-xr-x 7 ec2-user ec2-user       105 May  3 12:56 kafka_2.12-3.2.0
-rw-rw-r-- 1 ec2-user ec2-user 104000785 May 10 07:42 kafka_2.12-3.2.0.tgz

$ cd kafka_2.12-3.2.0
```

#### 2) 카프카 브로커 힙 메모리 설정 (KAFKA_HEAP_OPTS)

* 카프카 브로커는 레코드의 내용은 페이지 캐시로 시스템 메모리를 사용하고, 나머지 객체들은 힙 메모리에 저장하여 사용한다.<br>
→ 카프카 브로커를 운영할 때 힙 메모리를 5GB 이상으로 설정하지 않는다.
* 카프카 패키지의 default 힙 메모리 - 카프카 브로커 1G, 주키퍼 512MB
* 실습용 인스턴스(ec2.micro)는 1G 메모리를 가지고 있으므로, 카프카 브로커와 주키퍼를 기본 설정과 함께 동시에 실행하면 1.5 G 메모리가 필요하기 때문에 Caannot allocate memory 에러가 발생한다.

```bash
$ export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
$ echo $KAFKA_HEAP_OPTS
-Xmx400m -Xms400m
```

* 환경 변수 선언문을 ~./bashrc 파일에 넣어, 터미널 세션이 종료되고 나서도 재사용 할 수 있도록 한다.
    * ~./bashrc 파일 - bash 쉘이 실행될 때마다 반복적으로 구동되어 적용되는 파일이다.
    * bashrc 파일은 /etc 에 있다.
    * 리눅스 환경 변수 참고 - https://velog.io/@bonjaski0989/%EB%A6%AC%EB%88%85%EC%8A%A4-%ED%99%98%EA%B2%BD%EB%B3%80%EC%88%98-1-bashprofile-bashrc

```bash
$ vi ~/.bashrc
$ source ~/.bashrc # 스크립트 파일을 수정한 후 값을 바로 적용
$ echo $KAFKA_HEAP_OPTS
-Xmx400m -Xms400m
```
 
```bash
# .bashrc

# Source global definitions
if [ -f /etc/bashrc ]; then
        . /etc/bashrc
fi

# Uncomment the following line if you don't like systemctl's auto-paging feature:
# export SYSTEMD_PAGER=

# User specific aliases and functions
export KAFKA_HEAP_OPTS="-Xms400m -Xms400m"
```

* 카프카 브로커 실행시 메로리를 설정하는 부분 확인 - kafka-server-start.sh
    * 기본 힙 메모리: Xmx 1G, Xms 1G
    * -daemon 옵션: 백그라운드로 실행 (세션이 끊기더라도 계속 동작))

```bash
$ pwd /home/ec2-user/kafka_2.12-3.2.0/bin
$ cat kafka-server-start.sh
```

```bash
#!/bin/bash
# ...

if [ $# -lt 1 ];
then
        echo "USAGE: $0 [-daemon] server.properties [--override property=value]*"
        exit 1
fi
base_dir=$(dirname $0)

if [ "x$KAFKA_LOG4J_OPTS" = "x" ]; then
    export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$base_dir/../config/log4j.properties"
fi

if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
fi

EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc'}

COMMAND=$1
case $COMMAND in
  -daemon)
    EXTRA_ARGS="-daemon "$EXTRA_ARGS
    shift
    ;;
  *)
    ;;
esac

exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
```

#### 3) 카프카 브로커 실행 옵션 설정 - config/server.properties

* 설정한 옵션은 카프카 브로커를 실행할 때 kafka-server-start.sh 명령어와 함께 지정한다.
* 설정 변경시 브로커를 재시작해야 한다.

```bash
# ...
############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
# 실행하는 카프카의 번호, 클러스터 구축시 브로커 구분
broker.id=0

############################# Socket Server Settings #############################

# IP, port, 프로토콜 설정
listeners=PLAINTEXT://:9092

# 카프카 클라이언트 OR 커맨트 라인 툴을 브로커와 연결할 때 사용
advertised.listeners=PLAINTEXT://{ec2.host.name}:9092

# 보안 설정시 프로토콜 맵핑
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# 네트워크 스레드 개수
num.network.threads=3

# 카푸카 내부에서 사용할 스레드 개수
num.io.threads=8

# ...

############################# Log Basics #############################

# 통신을 통해 가져온 데잍어를 파일로 저장할 디렉토리 위치
log.dirs=/tmp/kafka-logs

# default 파티션 개수, 파티션이 많아지면 병렬처리 데이터양이 늘어난다.
num.partitions=1

# ...

############################# Log Retention Policy #############################

# 카프카 브로커가 저장한 파일이 삭제되기까지 걸리는 시간
# log.retention.ms를 추천, -1일 때에는 영구 보존된다.
log.retention.hours=168

# 카프카 브로커가 저장할 파일의 최대 크기, 이후 새로운 파일이 생성된다.
log.segment.bytes=1073741824

# 카프카 브로커가 저장한 파일을 삭제하기 위해 체크하는 간격
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection
# 실습시 EC2에 주키퍼와 카프커 브로커를 동시에 실행하므로 localhost로 설정하였다.
zookeeper.connect=localhost:2181

# Session Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=18000

```

#### 4) 주키퍼 실행

* 주키퍼
    * 분산 코디네이션 서비스를 제공
    * 카프카의 클러스터 설정 리더 정보, 컨트롤러 정보를 담고 있다.
    * 운영시 3대 이상의 서버로 구성한다.
* 주키퍼를 백그라운드 모드로 실행

```bash
$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```

* 주키퍼가 정상적으로 실행되었는지 jsp 명령어로 확인
    * jsp: JVM 프로세스 상태를 보는 도구
    * JVM 위에서 동작하는 주키퍼의 프로세스를 확인한다.
    * 옵션
         * -m: main 메서드에 전달된 인자 확인
         * -v: JVM에 전달된 인자 확인(힙 메모리 설정, log4j 설정)

```bash
$ jps -vm
24820 Jps -vm -Dapplication.home=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.amzn2.0.2.x86_64 -Xms8m
24503 QuorumPeerMain config/zookeeper.properties -Xmx400m -Xms400m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xloggc:/home/ec2-user/kafka_2.12-3.2.0/bin/../logs/zookeeper-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/home/ec2-user/kafka_2.12-3.2.0/bin/../logs -Dlog4j.configuration=file:bin/../config/log4j.properties
```

#### 5) 카프카 브로커 실행 및 로그 확인

* 카프카 브로커를 백그라운드 모드로 실행
* 카프파 클라이언트 개발 / 클러스터 운영시 이슈 발생하면 모두 카프카 브로커에 로그가 남는다.

```bash
$ bin/kafka-server-start.sh -daemon config/server.properties

$ jps -m
26497 Kafka config/server.properties
27157 Jps -m
24503 QuorumPeerMain config/zookeeper.properties

$ tail -f logs/server.log
```

### 1.5. 로컬 컴퓨터에서 카프카와 통신 확인 (로컬에서 카프카 브로커 정보 요청하기)

* kafka-broker-api-versions.sh : 카프카 바이너리 패키지는 카프카 브로커에 대한 정보를 가져올 수 있는 명령어를 제공한다.
* 로컬 컴퓨터(mac)에 카프카 바이너리 패키지를 다운로드하여 명령어를 실행하자.

```bash
$ curl https://dlcdn.apache.org/kafka/3.2.0/kafka_2.12-3.2.0.tgz --output kafka_2.12-3.2.0.tgz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 99.1M  100 99.1M    0     0  11.0M      0  0:00:08  0:00:08 --:--:-- 11.1M

$ tar -xvf kafka_2.12-3.2.0.tgz
```

* 로컬에서 원격으로 카프카의 정보 확인

```bash
$ bin/kafka-broker-api-versions.sh --bootstrap-server 54.180.108.166:9092
54.180.108.166:9092 (id: 0 rack: null) -> (
	Produce(0): 0 to 9 [usable: 9],
	Fetch(1): 0 to 13 [usable: 13],
	ListOffsets(2): 0 to 7 [usable: 7],
	Metadata(3): 0 to 12 [usable: 12],
	LeaderAndIsr(4): 0 to 6 [usable: 6],
	StopReplica(5): 0 to 3 [usable: 3],
...
```

* 오류 발생시 확인: https://blog.voidmainvoid.net/m/419/comments

### 1.6. 테스트 편의를 위한 hosts 설정

* 맥 - /etc/hosts
* 이 책의 실습에서는 `my-kafka` 라는 문장으로 매핑하여 통신한다.

## 2. 카프카 커맨드 라인 툴

### 2.1. kafka-topics.sh

* 토픽(topic): 카프카에서 데이터를 구분하는 가장 기본적인 개념 (RDBMS의 테이블과 유사)
    * 카프카 클러스터에 토픽은 여러 개 존재할 수 있다.
* 토픽에는 파티션(partition)이 존재한다.
    * 파티션을 통해 한 번에 처리할 수 있는 데이터 양을 늘릴 수 있다.
    * 토픽 내부에서도 파티션을 통해 데이터의 종류를 나누어 처리할 수 있다.
* 토픽마다 처리되어야 하는 데이터의 특성이 다르므로, 커맨드 라인 툴로 명시적으로 토픽을 생성하는 것이 좋다.

#### 1) 토픽 생성 (--create)

```bash
$ bin/kafka-topics.sh \
		--create \
		--bootstrap-server my-kafka:9092 \
		--topic hello.kafka \   # topic Name(자세히 명시해야 유지 보수가 편하다.)
```

```bash
        $ bin/kafka-topics.sh \
		--create \
		--bootstrap-server my-kafka:9092 \
		--partitions 3 \
		--replication-factor 1 \            # 파티션 복제 개수(1: 복제 안함, 2: 1개의 복제본)
		--config retention.ms=172800000 \   # kafka-topics.sh 명령에 포함되지 않은 추가 설정
		--topic hello.kafka.2 \
```

* 토픽 생성 시 --zookeeper가 아니라 --bootstrap-server 옵션을 사용하는 이유
    * 주키퍼와 직접 통신하여 명령을 처리하는 것은 아키텍처의 복잡도를 높이므로<br>
    카프카와 직접 통신하여 토픽 관련 명령을 실행한다.

#### 2) 토픽 리스트 조회 (--list)

```bash
	$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
```

#### 3) 토픽 상세 조회 (--describe)

```bash
    $ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2

Topic: hello.kafka.2	TopicId: 9LjkErU2T9Gnj_yYnjptLw	PartitionCount: 3	ReplicationFactor: 1	Configs: segment.bytes=1073741824,retention.ms=172800000
	Topic: hello.kafka.2	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: hello.kafka.2	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: hello.kafka.2	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
```

* Leader: 0 - 0번 브로커

#### 4) 토픽 옵션 수정 

* kafka-topics.sh: 파티션 개수 변경
* kafka-configs.sh: 토픽 삭제 정책(리텐션 기간) 변경 / dynamic topic config(log.segment.bytes/ms) 변경

```bash
    $ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
    > --topic hello.kafka \
    > --alter \
    > --partitions 4 \      # 파티션 개수 변경 (늘릴 수는 있지만 줄일 수는 없고, 번호는 0부터 시작한다.)

    bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
    > --topic hello.kafka \
    > --describe \

    bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
    > --entity-type topics \
    > --entity-name hello.kafka \
    > --alter --add-config retention.ms=86400000 \  # add-config: 설정을 upsert 한다.

    bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
    > --entity-type topics \
    > --entity-name hello.kafka \
    > --describe \
```

### 2.2. kafka-console-producer.sh

* 생성된 hello.kafka 토픽에 kafka-console-priduser.sh 명령어를 사용하여 데이터를 넣을 수 있다.
* record: 토픽에 넣는 데이터이며, 메시지 key/value로 구성된다.
* 전송되는 레코드 값은 UTF-8을 기반으로 Byte로 변환되고 ByteArraySerializer로만 직렬화된다.
    * 즉, String 이 아닌 타입으로는 직렬화하여 전송할 수 없다.
    * 다른 타입으로 직렬화하ㅓ여 데이터를 브로커로 전송하고 싶다면, 카프카 프로듀서 애플리케이션을 직접 개발해야 한다.

```bash
	$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka
    > hello
    > kafka # 엔터 키를 누르면 별다른 응답 없이 메시지 값이 전송된다.

	$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka \
	> --property "parse.key=true" \ # 메시지 키 추가
	> --property "key.separator=:"  #메시지 키와 메시지 값을 구분하는 구분자 (기본은 \t)
	>key1:no1
	>key2:no2
	>key3:no3
```

![파티션과레코드](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FciJpVN%2FbtqExs4sS5U%2FMEVHcyFScHXj1KSSvG2HU1%2Fimg.png)

* 레코드는 토픽의 파티션에 (메기지 키/값 pair로) 저장된다. 위 그림에서는 숫자가 레코드의 오프셋이다.

### 2.3. kafka-console-consumer.sh

* hello.kafka 토픽으로 전송한 데이터를 kafka-console-consumer.sh 명령어로 확인할 수 있다.
* 필수 옵션으로 --bootstrap-server에 카프카 클러스터 정보, --topic에 토픽 이름이 필요하다.

```bash
	$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka \
	> --from-beginning

	$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka \
	> --property print.key=true \       # 메시지 키를 확인하기 위함.
	> --property key.separator="-" \
	> --group hello-group \             # 신규 컨슈머 그룹 생성.
	> --from-beginning                  # 토픽에 저장된 가장 처음 데이터부터 출력.
```

* 컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 commit을 한다.
* commit: 커밋이란 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 카프카 브로커에 저장하는 것
* kafka-console-producer.sh로 전송했던 데이터의 순서가 현재 출력되는 순서와 다르다.
    * 컨슈머가 토픽의 데이터를 가져갈 때, 토픽의 모든 파티션으로부터 동일한 중요도로 데이터를 가져가기 때문이다.
    * 토픽에 넣은 데이터의 순서를 보장하고 싶다면 파티션 1개로 구성된 토픽을 만들면 된다.

### 2.4. kafka-consumer-groups.sh

* 생성된 컨슈머 그룹의 리스트를 확인한다.

```bash
	$ bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list

	$ bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 \
	> group hello-group \
	> --describe group

Consumer group 'hello-group' has no active members.

GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
hello-group     hello.kafka     0          10              10              0               -               -               -
```

### 2.5. kafka-verifiable-producer, consumer.sh

* kafka-verifiable로 시작하는 2개의 스크립트를 사용하면 String 타입 메시지 값을 코드 없이 주고받을 수 있다.
* 간단한 네트워크 통신 테스트 할 때 유용하다.

```bash
	$ bin/kafka-verifiable-producer.sh --bootstrap-server my-kafka:9092 \
	> --max-messages 10 \   # 데이터 개수 지정
	> --topic verify-test   # 데이터를 받을 대상 토픽

	$ bin/kafka-verifiable-consumer.sh --bootstrap-server my-kafka:9092 \
	> --topic verify-test \ # 데이터를 가져오고자 하는 토픽
	> --group-id test-group # 컨슈머 그룹 지정
```

### 2.6. kafka-delete-records.sh

* 이미 적재된 토픽의 데이터를 지운다.
* 이미 적재된 토픽의 데이터중 가장 오래된 데이터부터 특정 시점의 오프셋까지 삭제 가능하다.
* 카프카에서는 토픽의 파티션에 저장된 특정 데이터만 삭제할 수는 없다!

```bash
	$ vi delete-topic.json  # 삭제하고자 하는 데이터 정보
	{"partitions": [{"topic":"hello.kafka", "partition":0, "offset":3}], "version":1}

	$ bin/kafka-delete-records.sh --bootstrap-server my-kafka:9092 \
	> --offset-json-file delete-topic.json

Executing records delete operation
Records delete operation completed:
partition: hello.kafka-0	low_watermark: 3
```






